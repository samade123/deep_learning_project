{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Universal adversarial perturbations by Samuel ademola.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/Qq3Fs1eANYSU9JnBsb1r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samade123/deep_learning_project/blob/main/Universal_adversarial_perturbations_by_Samuel_ademola.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8t_EdO8jEHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be3cd32-19d2-41b1-e2b9-a3794024c6cb"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "# !pip install progress\n",
        "# load tqdm\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
        "\n",
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cleverhans\n",
        "keras.__version__\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "# from progress.bar import Bar\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cleverhans from git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans in /usr/local/lib/python3.7/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.0)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (from cleverhans) (2.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.1)\n",
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "  Using cached https://github.com/chengs/tqdm/archive/colab.zip\n",
            "Building wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47868 sha256=481000a62a17f3467ca9bb9153d9eccd66393db6ed291a06a3930bad0ebfed61\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i63l4ch_/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
            "Successfully built tqdm\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed tqdm-4.28.1\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "\n",
            "Tensorflow Version: 2.4.1\n",
            "Cleverhans Version: 4.0.0-dda3ed9309fe3cd6d5b746c5c9c440d8\n",
            "WARNING:tensorflow:From <ipython-input-1-15e538ded199>:22: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDMO_7kS6Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f2456c-4c76-4907-e3d6-162522aef5c0"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('conv_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()\n",
        "# model = new_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 88)                50776     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 88)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                890       \n",
            "=================================================================\n",
            "Total params: 107,410\n",
            "Trainable params: 107,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b4-ID4aUjXM"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist  # load dataset\n",
        "\n",
        "(conv_train_images, conv_train_labels), (conv_test_images, conv_test_labels) = fashion_mnist.load_data()  # split into tetsing and training\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training\n",
        "\n",
        "\n",
        "conv_train_images = conv_train_images.reshape((60000, 28, 28, 1))\n",
        "conv_train_images = conv_train_images.astype('float32') / 255\n",
        "\n",
        "conv_test_images = conv_test_images.reshape((10000, 28, 28, 1))\n",
        "conv_test_images = conv_test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cV_tavxwOR6"
      },
      "source": [
        "\n",
        "# def show_convoluted_image(img, label, guess):\n",
        "#   plt.figure()\n",
        "#   plt.imshow(img, cmap=plt.cm.binary)\n",
        "#   plt.title(\"Expected: \" + label)\n",
        "#   plt.xlabel(\"Guess: \" + guess)\n",
        "#   plt.colorbar()\n",
        "#   plt.grid(False)\n",
        "#   plt.show()\n",
        "\n",
        "def show_convoluted_image(original_image, original_label, guess, model_status=False, guessList=[], predictions=[]):\n",
        "    #Show the image\n",
        "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "    plt.figure()\n",
        "    plt.grid(False)\n",
        "    # original_label = class_names[original_label]\n",
        "    # label = class_names[label]\n",
        "\n",
        "    plt.imshow(np.reshape(original_image, (28,28)), cmap=plt.cm.binary)\n",
        "    if model_status:\n",
        "        guess = \" \"\n",
        "    #     pred_label, pred_prob = top_k_predictions(img)\n",
        "        # for label, prob in zip(pred_label, pred_prob):\n",
        "        print( guessList)\n",
        "        guessList = np.array(guessList)\n",
        "        for label in guessList:\n",
        "    #         print(f'{label}: {prob:0.1%}')\n",
        "            print(label)\n",
        "            guess = f'{class_names[label]} : {round(predictions[label]*100, 2)}%,  {guess} ' \n",
        "            # guess = f'{guess + class_names[label-1]} : {prob:0.1%}, ' \n",
        "\n",
        "\n",
        "    plt.title(\"Original Label: \" + class_names[label])\n",
        "    plt.xlabel(\"Model Prediction: {}\".format(guess))\n",
        "    # plt.xlabel(\"Original Label: \" + class_names[label])\n",
        "    plt.show() \n",
        "\n",
        "\n",
        "def predict(model, image, correct_label, num):\n",
        "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "  prediction = model.predict(np.array([image]))\n",
        "  predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "#   print(prediction, predicted_class)\n",
        "  image = conv_test_images[num]\n",
        "  show_convoluted_image(image, class_names[correct_label], predicted_class)\n",
        "\n",
        "\n",
        "def get_number():\n",
        "  while True:\n",
        "    num = input(\"Pick a number: \")\n",
        "    if num.isdigit():\n",
        "      num = int(num)\n",
        "      if 0 <= num <= 1000:\n",
        "        return int(num)\n",
        "    else:\n",
        "      print(\"Try again...\")\n",
        "\n",
        "def select_number(num=0):\n",
        "    return_val = False\n",
        "    if num == 0:\n",
        "        num = get_number()\n",
        "        return_val = True\n",
        "    image = conv_test_images[num]\n",
        "    label = conv_test_labels[num]\n",
        "    predict(new_model, image, label, num)\n",
        "    if return_val:\n",
        "        return num\n",
        "\n",
        "\n",
        "# def random_predict(select_model):\n",
        "#     num = get_number()\n",
        "#     image = conv_test_images[num]\n",
        "#     label = conv_test_images[num]\n",
        "#     pred, predict_class = predict(select_model, image, label)\n",
        "#     return pred, predict_class\n",
        "# pred, predict_class = random_predict(model)\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEY-8X34OdM5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "c7c08437-ffb4-4963-c7da-65f3feb66be2"
      },
      "source": [
        "# select_number()\n",
        "\n",
        "def top_k_predictions(img, k=3):\n",
        "  image_batch = tf.expand_dims(img, 0)\n",
        "  predictions = model(image_batch)\n",
        "  probs = tf.nn.softmax(predictions, axis=-1)\n",
        "  top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
        "  top_labels = test_labels[tuple(top_idxs)]\n",
        "\n",
        "\n",
        "  return top_labels, top_probs[0]\n",
        "\n",
        "import re\n",
        "def truncate(num):\n",
        "    return re.sub(r'^(\\d+\\.\\d{,2})\\d*$',r'\\1',str(num))\n",
        "\n",
        "# def show_image(img, label, guess, model_status=False, guessList=[], predictions=[]):\n",
        "#   plt.figure()\n",
        "#   plt.imshow(img, cmap=plt.cm.binary)\n",
        "#   plt.title(\"Expected: \" + label)\n",
        "#   if model_status:\n",
        "#     guess = \" \"\n",
        "# #     pred_label, pred_prob = top_k_predictions(img)\n",
        "#     # for label, prob in zip(pred_label, pred_prob):\n",
        "#     print( guessList)\n",
        "#     guessList = np.array(guessList)\n",
        "#     for label in guessList:\n",
        "# #         print(f'{label}: {prob:0.1%}')\n",
        "#         print(label)\n",
        "#         guess = f'{class_names[label]} : {round(predictions[label]*100, 2)}%,  {guess} ' \n",
        "#         # guess = f'{guess + class_names[label-1]} : {prob:0.1%}, ' \n",
        "#   plt.xlabel(\"Guess: \" + guess)\n",
        "#   plt.colorbar()\n",
        "#   plt.grid(False)\n",
        "#   plt.show()\n",
        "\n",
        "def set_plot_color(color = 'white'):\n",
        "  plt.rcParams['text.color'] = color\n",
        "  plt.rcParams['axes.labelcolor'] = color\n",
        "  ax = plt.axes()\n",
        "  # Setting the background color\n",
        "  ax.set_facecolor(\"grey\")\n",
        "\n",
        "  \n",
        "\n",
        "def predict(model, image, correct_label, k=3):\n",
        "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "  prediction = new_model.predict(np.array([image]))\n",
        "  predicted_class = class_names[np.argmax(prediction)]\n",
        "\n",
        "  print(prediction, predicted_class)\n",
        "  guess = np.argpartition(prediction[0], -k)[-k:] \n",
        "  prediction[0][guess]\n",
        "  guess[np.argsort(prediction[0][guess])]\n",
        "#   guess = prediction[0].argsort()[-k:][::-1]\n",
        "  print(guess)\n",
        "\n",
        "  show_convoluted_image(image, class_names[correct_label], predicted_class, True, guess, prediction[0])\n",
        "# def show_convoluted_image(original_image, original_label, guess, model_status=False, guessList=[], predictions=[]):\n",
        "#\n",
        "  return prediction, predicted_class  \n",
        "\n",
        "def get_number():\n",
        "  while True:\n",
        "    num = input(\"Pick a number: \")\n",
        "    if num.isdigit():\n",
        "      num = int(num)\n",
        "      if 0 <= num <= 1000:\n",
        "        return int(num)\n",
        "    else:\n",
        "      print(\"Try again...\")\n",
        "\n",
        "def random_predict(select_model):\n",
        "    num = get_number()\n",
        "    image = conv_test_images[num]\n",
        "    label = test_labels[num]\n",
        "    pred, predict_class = predict(select_model, image, label)\n",
        "    return pred, predict_class\n",
        "# pred, predict_class = random_predict(model)\n",
        "pred, predict_class = random_predict(new_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pick a number: 280\n",
            "[[9.99726355e-01 1.91269645e-09 4.22253543e-05 2.10081969e-04\n",
            "  6.81578194e-06 9.69557941e-12 3.93678738e-06 6.26777727e-11\n",
            "  1.06565785e-05 3.92492159e-12]] T-shirt/top\n",
            "[2 3 0]\n",
            "[2 3 0]\n",
            "2\n",
            "3\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Ehc7tas5YS"
      },
      "source": [
        "#Part 2: The Fast Gradient Method (FGM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgZhvgzbAuU8"
      },
      "source": [
        "# Import the attack\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(new_model.input,new_model.layers[-1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giyjFKREs-nx"
      },
      "source": [
        "def fsgm(index, original_image,  epsilon = 0.03, verbose_log = False):\n",
        "    # original_image = conv_train_images[index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_image = np.expand_dims(original_image, axis=0)\n",
        "\n",
        "    original_label = train_labels[index]\n",
        "    original_label = np.reshape(original_label, (1,)).astype('int64') # Give label proper shape and type for cleverhans\n",
        "    if verbose_log == True:\n",
        "        select_number(index)\n",
        "        show_convoluted_image(original_image, original_label[0], original_label[0])\n",
        "    \n",
        "\n",
        "    adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "    adv_example_untargeted_label_pred = new_model.predict(adv_example_untargeted_label)\n",
        "\n",
        "    return adv_example_untargeted_label, adv_example_untargeted_label_pred\n",
        "\n",
        "def get_pertubation(original_image, adv_example_untargeted_label):\n",
        "    pertubation = original_image - adv_example_untargeted_label\n",
        "    return pertubation\n",
        "\n",
        "def get_max_prediction(model_predicition):\n",
        "    return model_predicition[0][np.argmax(model_predicition)]   \n",
        "\n",
        "def is_new_iamge_fooled(adv_prediction, prediction_old, fooling_rate, verbose_log = False):\n",
        "    if verbose_log == True:\n",
        "        print(\"fooling_rate\", fooling_rate)\n",
        "        print(\"adverse Image prediction: \" , np.argmax(adv_prediction) , \"val: \", np.max(adv_prediction)  ,\", origiinal Image prediction: \", np.argmax(prediction_old), \"val: \", np.max(prediction_old),  \", prediction accuracy greater than fooling rate: \", get_max_prediction(adv_prediction) > fooling_rate )\n",
        "        class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "        # table = pandas.DataFrame(adv_prediction.transpose(), class_names, ['old'])\n",
        "        # prediction_old = new_model.predict(original_image)\n",
        "        new_data = np.concatenate((adv_prediction, prediction_old))\n",
        "        table = pandas.DataFrame(new_data.transpose(), class_names, ['new', 'old'])\n",
        "        print(table)\n",
        "        print(np.max(adv_prediction/np.sum(adv_prediction))*100)\n",
        "        print(\"are max index the same\", (np.argmax(adv_prediction) != np.argmax(prediction_old), \", higher than foolng rte\", get_max_prediction(adv_prediction) > fooling_rate ))\n",
        "        print(\"is the adverse Image foolwortgy: \", (np.argmax(adv_prediction) != np.argmax(prediction_old)) and (get_max_prediction(adv_prediction) > fooling_rate ))\n",
        "        table.to_csv('data.csv')\n",
        "    return ((np.argmax(adv_prediction) != np.argmax(prediction_old)) and (get_max_prediction(adv_prediction) > fooling_rate ))  \n",
        "\n",
        "def minimum_fsgm(fooling_rate, original_image, random_index, verbose_log=False):\n",
        "    prediction_old = new_model.predict(original_image)\n",
        "\n",
        "    a_adv_pred = prediction_old\n",
        "    x_adv = original_image\n",
        "    # x_adv, a_adv_pred = fsgm(random_index)\n",
        "    itr = 2\n",
        "    max_attempts = 20\n",
        "    epislon_steps = 0.01\n",
        "    # current_fooling_rate = 0\n",
        "    # while \n",
        "\n",
        "    # if first_image == True:\n",
        "        # while ((np.argmax(a_adv_pred) == np.argmax(prediction_old)) or (get_max_prediction(a_adv_pred) < fooling_rate )):\n",
        "    status = True\n",
        "    if verbose_log:\n",
        "        print(\"does while statement run\", is_new_iamge_fooled(a_adv_pred, prediction_old, fooling_rate, False))\n",
        "    while is_new_iamge_fooled(a_adv_pred, prediction_old, fooling_rate, False) == False:\n",
        "        itr+= 1\n",
        "        if verbose_log:\n",
        "            print(itr , epislon_steps*itr, is_new_iamge_fooled(a_adv_pred, prediction_old, fooling_rate))\n",
        "        x_adv, a_adv_pred = fsgm(random_index, original_image, epislon_steps*itr)\n",
        "        if itr > max_attempts: \n",
        "            status = False\n",
        "            break\n",
        "\n",
        "    pertubation = get_pertubation(original_image, x_adv)\n",
        "    return pertubation, status\n",
        "\n",
        "\n",
        "def create_universerial_pertubations(loops = 10, fooling_rate=0.5, verbose_log =False):\n",
        "    image_index = 0\n",
        "    # fooling_rate = 0.9\n",
        "    pbar = tqdm(total=loops)\n",
        "\n",
        "    while image_index < loops:\n",
        "        random_index = np.random.randint(train_images.shape[0])\n",
        "        original_image = conv_train_images[random_index]\n",
        "        original_image = tf.convert_to_tensor(original_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "        original_image = np.expand_dims(original_image, axis=0)\n",
        "        # original_label = class_names[train_labels[random_index][0]]\n",
        "\n",
        "        prediction_old = new_model.predict(original_image)\n",
        "        # print(\"first_image\")\n",
        "        first_image = (image_index == 0)\n",
        "        # current_pertubation = minimum_fsgm(fooling_rate, first_image)\n",
        "        if first_image == True:\n",
        "            current_pertubation, status = minimum_fsgm(fooling_rate, original_image, random_index) #fix minimum fgsm function\n",
        "            show_convoluted_image(current_pertubation, original_label[0], original_label[0])\n",
        "\n",
        "            universal_pertubation = current_pertubation\n",
        "        else:\n",
        "            pertubated_img = original_image + universal_pertubation\n",
        "            prediction_old = new_model.predict(original_image)\n",
        "            predicion_pertubated = new_model.predict(pertubated_img)\n",
        "            if is_new_iamge_fooled(predicion_pertubated, prediction_old, fooling_rate, verbose_log):\n",
        "                # image_index+= 1\n",
        "                if verbose_log:\n",
        "                    print(\"image is fooled\", image_index)\n",
        "                # loops+= 1\n",
        "                \n",
        "            else: \n",
        "                current_pertubation, status = minimum_fsgm(fooling_rate, original_image, random_index)\n",
        "                if verbose_log:\n",
        "                    print(\"image is being pertubated\", image_index)\n",
        "                # attempt 1 - queit but not adverserial\n",
        "                # difference_pert =universal_pertubation - current_pertubation\n",
        "                # universal_pertubation = difference_pert - universal_pertubation\n",
        "\n",
        "                # attempt 2 - works but the pertubation is not qiuet\n",
        "                # difference_pert = np.abs(current_pertubation - universal_pertubation)\n",
        "                # universal_pertubation = universal_pertubation + difference_pert\n",
        "\n",
        "                # attempt 3 - works but the pertubation is not qiuet\n",
        "                # difference_pert = np.abs(universal_pertubation - current_pertubation)\n",
        "                # universal_pertubation = universal_pertubation + difference_pert\n",
        "\n",
        "                # difference_pert =  current_pertubation - universal_pertubation\n",
        "                # universal_pertubation = universal_pertubation + difference_pert\n",
        "\n",
        "                # attempt 4 - not yet tested\n",
        "                # difference_pert = np.abs(universal_pertubation - current_pertubation)\n",
        "                # universal_pertubation = np.abs(difference_pert - universal_pertubation)\n",
        "\n",
        "                 # attempt 4 - not yet tested\n",
        "                # difference_pert = universal_pertubation - current_pertubation\n",
        "                # universal_pertubation = np.abs(universal_pertubation - difference_pert)\n",
        "\n",
        "                # universal_pertubation = universal_pertubation + current_pertubation\n",
        "               \n",
        "                universal_pertubation =np.abs(universal_pertubation - current_pertubation)\n",
        "\n",
        "                # universal_pertubation =np.abs(current_pertubation - universal_pertubation)\n",
        "\n",
        "                if verbose_log:\n",
        "                    # show_convoluted_image(difference_pert, original_label[0], original_label[0])\n",
        "                    # show_convoluted_image(pertubated_img, original_label[0], original_label[0])\n",
        "                    show_convoluted_image(current_pertubation, original_label[0], original_label[0])\n",
        "                    show_convoluted_image(universal_pertubation, original_label[0], original_label[0])\n",
        "\n",
        "                # image_index+= 1\n",
        "\n",
        "\n",
        "        if status == True:\n",
        "            image_index+= 1\n",
        "            pbar.update(1)\n",
        "    pbar.close()\n",
        "    # if verbose_log:\n",
        "    show_convoluted_image(universal_pertubation, original_label[0], original_label[0])\n",
        "    return universal_pertubation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA7_JKrm1wsm"
      },
      "source": [
        "random_index = np.random.randint(train_images.shape[0])\n",
        "\n",
        "original_image = conv_train_images[random_index]\n",
        "original_image = tf.convert_to_tensor(original_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "original_image = np.expand_dims(original_image, axis=0)\n",
        "prediction_old = new_model.predict(original_image)\n",
        "original_label = train_labels[random_index]\n",
        "original_label = np.reshape(original_label, (1,)).astype('int64') # Give label proper shape and type for cleverhans\n",
        "\n",
        "# #Show the image\n",
        "# plt.figure()\n",
        "# plt.grid(False)\n",
        "\n",
        "# plt.imshow(np.reshape(original_image, (28,28)))\n",
        "# plt.title(\"Label: {}\".format(original_label[0]))\n",
        "\n",
        "# plt.show()\n",
        "# select_number(random_index)\n",
        "show_convoluted_image(original_image, original_label[0], original_label[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz8QBZJ2-DO5"
      },
      "source": [
        "### Non-targeted FGSM attack\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LSemuYWrZWz"
      },
      "source": [
        "epsilon = 0.05\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "adv_example_untargeted_label_pred = new_model.predict(adv_example_untargeted_label)\n",
        "\n",
        "# #Show the image\n",
        "# plt.figure()\n",
        "# plt.grid(False)\n",
        "\n",
        "# plt.imshow(np.reshape(adv_example_untargeted_label, (28,28)))\n",
        "# plt.title(\"Model Prediction: {}\".format(np.argmax(adv_example_untargeted_label_pred)))\n",
        "# plt.xlabel(\"Original Label: {}\".format(original_label[0]))\n",
        "\n",
        "# plt.show()\n",
        "# print(\"Prediction\", adv_example_untargeted_label_pred)\n",
        "show_convoluted_image(adv_example_untargeted_label, original_label[0], np.argmax(adv_example_untargeted_label_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As2izllk0sIO"
      },
      "source": [
        "pertubation = original_image - adv_example_untargeted_label\n",
        "# #Show the image\n",
        "# plt.figure()\n",
        "# plt.grid(False)\n",
        "\n",
        "# plt.imshow(np.reshape(pertubation, (28,28)))\n",
        "# plt.title(\"Model Prediction: {}\".format(np.argmax(adv_example_untargeted_label_pred)))\n",
        "# plt.xlabel(\"Original Label: {}\".format(original_label[0]))\n",
        "\n",
        "# plt.show()\n",
        "show_convoluted_image(pertubation, original_label[0], np.argmax(adv_example_untargeted_label_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B00oKIK9gIF-"
      },
      "source": [
        "# is_new_iamge_fooled(adv_example_untargeted_label_pred, prediction_old, 0.6, True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AitPJwZ4c6y"
      },
      "source": [
        " y, r = minimum_fsgm(0.8, original_image, random_index, True)\n",
        " print(r)\n",
        " pertubed = original_image + y\n",
        "show_convoluted_image(y, original_label[0], np.argmax(adv_example_untargeted_label_pred))\n",
        "show_convoluted_image(pertubed, original_label[0], np.argmax(adv_example_untargeted_label_pred))\n",
        "pertubed_min_pred = new_model.predict(pertubed)\n",
        "\n",
        "\n",
        "is_new_iamge_fooled(pertubed_min_pred, prediction_old, 0.4, True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6cLe7F7C5yi"
      },
      "source": [
        "universal = create_universerial_pertubations(50, 0.1, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsbWz087FlqZ"
      },
      "source": [
        "def test_universal(universal):\n",
        "    random_index = np.random.randint(test_images.shape[0])\n",
        "    original_image = conv_test_images[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_image = np.expand_dims(original_image, axis=0)\n",
        "    original_label = test_labels[random_index]\n",
        "    original_label = np.reshape(original_label, (1,)).astype('int64') # Give label proper shape and type for cleverhans\n",
        "\n",
        "    new_image = original_image + universal\n",
        "\n",
        "    prediction_old = new_model.predict(original_image)\n",
        "    prediction_new = new_model.predict(new_image)\n",
        "\n",
        "    is_new_iamge_fooled(prediction_new, prediction_old, 0.4, True)\n",
        "    show_convoluted_image(new_image, original_label[0], np.argmax(prediction_new))\n",
        "    show_convoluted_image(original_image, original_label[0], np.argmax(prediction_old))\n",
        "\n",
        "\n",
        "test_universal(universal)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbFautFdXu4O"
      },
      "source": [
        "# Debugging errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjcOzyyZWvQ"
      },
      "source": [
        "old_images = conv_test_images\n",
        "# for x in conv_test_images:\n",
        "#     # image = x\n",
        "#     # image = image + universal\n",
        "#     # show_convoluted_image(image, original_label[0], np.argmax(prediction_old))\n",
        "#     x = x + universal\n",
        "#     # show_convoluted_image(x, original_label[0], np.argmax(prediction_old))\n",
        "loops = 1000\n",
        "fooled = 0\n",
        "pbar = tqdm(total=loops)\n",
        "for x in range(loops):\n",
        "    original_image = conv_test_images[x] + universal\n",
        "    old_image = old_images[x]\n",
        "\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_image = np.expand_dims(original_image, axis=0)\n",
        "\n",
        "    old_image = tf.convert_to_tensor(old_image.reshape((28,28,1))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    old_image = np.expand_dims(old_image, axis=0)\n",
        "\n",
        "    new_predict = new_model.predict(original_image)\n",
        "    old_predict = new_model.predict(old_image)\n",
        "    # print(np.argmax(old_predict), np.argmax(new_predict))\n",
        "    # show_convoluted_image(original_image, original_label[0], np.argmax(prediction_old))\n",
        "    # show_convoluted_image(old_image, original_label[0], np.argmax(prediction_old))\n",
        "    if np.argmax(old_predict) != np.argmax(new_predict):\n",
        "        fooled+= 1\n",
        "        # print(\"fooled\",fooled)\n",
        "    pbar.update(1)\n",
        "\n",
        "\n",
        "test_loss, test_acc = new_model.evaluate(conv_test_images,  test_labels, verbose=1)\n",
        "pbar.close()\n",
        "# show_convoluted_image(noise[60], original_label[0], np.argmax(prediction_old))\n",
        "# show_convoluted_image(test_images[34], original_label[0], np.argmax(prediction_old))\n",
        "print(test_loss, test_acc)\n",
        "print(\"fooled: \",fooled)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JusoumxLWhVQ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "def valid_imshow_data(data):\n",
        "    data = np.asarray(data)\n",
        "    if data.ndim == 2:\n",
        "        return True\n",
        "    elif data.ndim == 3:\n",
        "        if 3 <= data.shape[2] <= 4:\n",
        "            return True\n",
        "        else:\n",
        "            print('The \"data\" has 3 dimensions but the last dimension '\n",
        "                  'must have a length of 3 (RGB) or 4 (RGBA), not \"{}\".'\n",
        "                  ''.format(data.shape[2]))\n",
        "            return False\n",
        "    else:\n",
        "        print('To visualize an image the data must be 2 dimensional or '\n",
        "              '3 dimensional, not \"{}\".'\n",
        "              ''.format(data.ndim))\n",
        "        return False\n",
        "\n",
        "valid_imshow_data(conv_test_images[3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxz0v3bcX7AD"
      },
      "source": [
        "If the code above returns false then there is something likely wrong with the image data "
      ]
    }
  ]
}